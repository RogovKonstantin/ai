m— это количество обучающих примеров (то есть строк в наборе данных).
Оно используется для нормализации различных вычислений:

В функции стоимости чтобы ошибка учитывала размер данных

В градиентном спуске позволяет корректно масштабировать сумму ошибок независимо
от количества примеров и сделать обновление масштабирующимся с ростом данных

X (матрица признаков):
Размерность X — m×(n+1), где m — количество примеров, n — количество признаков,
а дополнительный столбец единиц добавляется для учёта свободного члена theta0.

Y (вектор истинных значений):
Размерность Y — m×1.

θ (вектор параметров):
Размерность θ — (n+1)×1. Это вектор весов модели, соответствующий каждому признаку включая свободный член theta0.

выражение np.dot(errors, errors) выполняет вычисление скалярного произведения вектора ошибок на самого себя.
Это используется для нахождения суммы квадратов ошибок. Это эквивалентно сумме квадратов всех ошибок. Результат — скалярное значение.

Во время выполнения градиентного спуска параметры θ обновляются в каждом шаге, чтобы минимизировать значение функции стоимости J(θ).
Это итеративно обновляет вектор параметров θ, приближая его к значениям, которые минимизируют
ошибку между предсказаниями модели и истинными значениями.
В итоге, после оптимального числа итераций, θθ становится близким к идеальному набору параметров, подходящих для данных.


Добавление столбца единиц в X необходимо для учёта свободного члена theta0 (сдвига).
Если столбец единиц не добавить, то:
Модель будет проходить через начало координат.
Мы не сможем учесть влияние сдвига theta0 на предсказания.
Однако можно обойтись без добавления столбца,
если модифицировать формулы для учёта theta0 отдельно от остальных параметров.
В этом случае theta0 можно обновлять отдельно, но это делает вычисления сложнек.
Поэтому добавление столбца единиц в X — наиболее удобный и распространённый метод.

Если данные таковы, что для увеличения количества автомобилей (признак X) прибыль (целевая переменная Y) уменьшается,
то модель покажет отрицательный коэффициент для признака, чтобы отразить эту связь.


Таким образом:
Наличие отрицательных значений в θ при градиентном спуске — это нормальное явление.
Модель будет "искать" такие значения θ, которые лучше всего соответствуют данным и минимизируют функцию стоимости.

Если данные показывают отрицательную зависимость между признаком и целевой переменной,
соответствующий параметр θ скорее всего станет отрицательным.